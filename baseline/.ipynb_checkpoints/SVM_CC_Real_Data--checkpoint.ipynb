{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: -: No such file or directory\r\n",
      "ls: al: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls- al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11360\r\n",
      "drwxr-xr-x@  9 chengjielin  staff      288 Apr 26 20:25 \u001b[34m.\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x@ 20 chengjielin  staff      640 Nov 12 14:31 \u001b[34m..\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   4 chengjielin  staff      128 Apr 26 20:25 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m/\r\n",
      "-rwxr-xr-x@  1 chengjielin  staff  5617630 Aug 25  2016 \u001b[31mCombined_News_DJIA.csv\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@  1 chengjielin  staff   167083 Aug 25  2016 \u001b[31mDJIA_table.csv\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@  1 chengjielin  staff      244 Jun 19  2017 \u001b[31mREADME.md\u001b[m\u001b[m*\r\n",
      "-rw-r--r--   1 chengjielin  staff       72 Apr 26 20:25 Untitled.ipynb\r\n",
      "-rwxr-xr-x@  1 chengjielin  staff     2140 Nov 12 16:03 \u001b[31mbaseline.py\u001b[m\u001b[m*\r\n",
      "-rw-r--r--   1 chengjielin  staff    15140 Nov 20 10:33 untiltled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess\n",
      "(1989, 27)\n",
      "avg\n",
      "[[-0.30944 ]\n",
      " [-0.12074 ]\n",
      " [-0.217556]\n",
      " ..., \n",
      " [-0.24054 ]\n",
      " [-0.280596]\n",
      " [-0.338272]]\n",
      "(1989, 1)\n",
      "sentiment_include\n",
      "(1989, 28)\n",
      "train_set\n",
      "(1610, 28)\n",
      "train_labels\n",
      "(1610,)\n",
      "train_sentiments\n",
      "(1610, 1)\n",
      "(1610, 1)\n",
      "(1610,)\n",
      "Training done.\n",
      "0.5079365079365079\n",
      "[ 0.50649351  0.52631579  0.50666667  0.50666667  0.50666667]\n",
      "Avg = 0.510561859193\n",
      "Cross validation done.\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# %load baseline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def import_data(filename):\n",
    "\treturn pd.read_csv(filename, header=0).fillna('').values\n",
    "\n",
    "def pre_process(data):\n",
    "\tfor row in data[0:476]:\n",
    "\t\tfor field in row[2:]:\n",
    "\t\t\tif not field == '':\n",
    "\t\t\t\tfield = field[1:]\t# Remove first 'b'\n",
    "\tprint(\"preprocess\")\n",
    "\t#print(data)\n",
    "\tprint(data.shape)\n",
    "\treturn data\n",
    "\n",
    "def add_avg_sentiment(data):\n",
    "\tsid = SentimentIntensityAnalyzer()\n",
    "\tavgs = np.empty((len(data),1))\n",
    "\tfor i in range(0,len(data)):\n",
    "\t\tsentiments = []\n",
    "\t\tfor field in data[i][2:]:\n",
    "\t\t\tsentiments.append(sid.polarity_scores(field)['compound'])\n",
    "\t\tavg = float(sum(sentiments))/len(sentiments)\n",
    "\t\tavgs[i] = avg\n",
    "\tprint(\"avg\")\n",
    "\tprint(avgs)\n",
    "\tprint(avgs.shape)\n",
    "\treturn np.append(data, avgs, axis=1)\n",
    "\n",
    "def divide_train_test(data):\n",
    "\ttrain = data[:1610]\n",
    "\ttest = data[1611:]\n",
    "\treturn train, test\n",
    "\n",
    "def train(data, labels):\n",
    "\tprint(data.shape)\n",
    "\tprint(labels.shape)\n",
    "\treturn svm.SVC(kernel='linear', C=1).fit(data, labels)\n",
    "\n",
    "def cross_validate(data, labels, clsfr):\n",
    "\treturn cross_val_score(clsfr, data, labels, cv=5)\n",
    "\n",
    "def main():\n",
    "\tdata = import_data(\"Combined_News_DJIA.csv\")\n",
    "\tpre_processed = pre_process(data)\n",
    "\tsentiment_included = add_avg_sentiment(pre_processed)\n",
    "\tprint(\"sentiment_include\")\n",
    "\tprint(sentiment_included.shape)\n",
    "\ttrain_set, test_set = divide_train_test(sentiment_included)\n",
    "\tprint(\"train_set\")\n",
    "\tprint(train_set.shape)\n",
    "\ttrain_labels = train_set[:,1].ravel()\n",
    "\tprint(\"train_labels\")\n",
    "\tprint(train_labels.shape)\n",
    "\ttrain_sentiments = train_set[:,27].reshape(len(train_set), 1)\n",
    "\tprint(\"train_sentiments\")\n",
    "\tprint(train_sentiments.shape)\n",
    "\ttest_labels = test_set[:,1].ravel()\n",
    "\ttest_sentiments = test_set[:,27].reshape(len(test_set),1)\n",
    "\n",
    "\tclsfr = train(train_sentiments, train_labels.astype('int'))\n",
    "\tprint(\"Training done.\")\n",
    "\tresults = cross_validate(test_sentiments, test_labels.astype('int'), clsfr)\n",
    "\tprint(test_labels.mean())\n",
    "\tprint(results)\n",
    "\tprint(\"Avg = \" + str(results.mean()))\n",
    "\tprint(\"Cross validation done.\")\n",
    "\tclsfr.predict(test_sentiments[:10])print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess\n",
      "(1989, 27)\n",
      "avg\n",
      "[[-0.30944 ]\n",
      " [-0.12074 ]\n",
      " [-0.217556]\n",
      " ..., \n",
      " [-0.24054 ]\n",
      " [-0.280596]\n",
      " [-0.338272]]\n",
      "(1989, 1)\n",
      "sentiment_include\n",
      "(1989, 28)\n",
      "train_set\n",
      "(1610, 28)\n",
      "train_labels\n",
      "(1610,)\n",
      "train_sentiments\n",
      "(1610, 1)\n",
      "(1610, 1)\n",
      "(1610,)\n",
      "Training done.\n",
      "0.5079365079365079\n",
      "[ 0.50649351  0.52631579  0.50666667  0.50666667  0.50666667]\n",
      "Avg = 0.510561859193\n",
      "Cross validation done.\n",
      "prediction shape\n",
      "(1610,)\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[0 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# %load baseline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def import_data(filename):\n",
    "\treturn pd.read_csv(filename, header=0).fillna('').values\n",
    "\n",
    "def pre_process(data):\n",
    "\tfor row in data[0:476]:\n",
    "\t\tfor field in row[2:]:\n",
    "\t\t\tif not field == '':\n",
    "\t\t\t\tfield = field[1:]\t# Remove first 'b'\n",
    "\tprint(\"preprocess\")\n",
    "\t#print(data)\n",
    "\tprint(data.shape)\n",
    "\treturn data\n",
    "\n",
    "def add_avg_sentiment(data):\n",
    "\tsid = SentimentIntensityAnalyzer()\n",
    "\tavgs = np.empty((len(data),1))\n",
    "\tfor i in range(0,len(data)):\n",
    "\t\tsentiments = []\n",
    "\t\tfor field in data[i][2:]:\n",
    "\t\t\tsentiments.append(sid.polarity_scores(field)['compound'])\n",
    "\t\tavg = float(sum(sentiments))/len(sentiments)\n",
    "\t\tavgs[i] = avg\n",
    "\tprint(\"avg\")\n",
    "\tprint(avgs)\n",
    "\tprint(avgs.shape)\n",
    "\treturn np.append(data, avgs, axis=1)\n",
    "\n",
    "def divide_train_test(data):\n",
    "\ttrain = data[:1610]\n",
    "\ttest = data[1611:]\n",
    "\treturn train, test\n",
    "\n",
    "def train(data, labels):\n",
    "\tprint(data.shape)\n",
    "\tprint(labels.shape)\n",
    "\treturn svm.SVC(kernel='linear', C=1).fit(data, labels)\n",
    "\n",
    "def cross_validate(data, labels, clsfr):\n",
    "\treturn cross_val_score(clsfr, data, labels, cv=5)\n",
    "\n",
    "def main():\n",
    "\tdata = import_data(\"Combined_News_DJIA.csv\")\n",
    "\tpre_processed = pre_process(data)\n",
    "\tsentiment_included = add_avg_sentiment(pre_processed)\n",
    "\tprint(\"sentiment_include\")\n",
    "\tprint(sentiment_included.shape)\n",
    "\ttrain_set, test_set = divide_train_test(sentiment_included)\n",
    "\tprint(\"train_set\")\n",
    "\tprint(train_set.shape)\n",
    "\ttrain_labels = train_set[:,1].ravel()\n",
    "\tprint(\"train_labels\")\n",
    "\tprint(train_labels.shape)\n",
    "\ttrain_sentiments = train_set[:,27].reshape(len(train_set), 1)\n",
    "\tprint(\"train_sentiments\")\n",
    "\tprint(train_sentiments.shape)\n",
    "\ttest_labels = test_set[:,1].ravel()\n",
    "\ttest_sentiments = test_set[:,27].reshape(len(test_set),1)\n",
    "\n",
    "\tclsfr = train(train_sentiments, train_labels.astype('int'))\n",
    "\tprint(\"Training done.\")\n",
    "\tresults = cross_validate(test_sentiments, test_labels.astype('int'), clsfr)\n",
    "\tprint(test_labels.mean())\n",
    "\tprint(results)\n",
    "\tprint(\"Avg = \" + str(results.mean()))\n",
    "\tprint(\"Cross validation done.\")\n",
    "\tpred=clsfr.predict(train_sentiments)\n",
    "\tprint(\"prediction shape\")\n",
    "\tprint(pred.shape)\n",
    "\tprint(pred)\n",
    "\tprint(train_labels[0:10])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
